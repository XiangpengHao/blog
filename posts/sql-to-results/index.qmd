---
title: "What happens when you type a SQL in the database"
date: "2024-04-26"
date-modified: "2024-04-30"
categories: []
toc: true
format:
  html: 
    highlight-style: tango 
---

## Preface 
A database can be complex; it involves almost all aspects (research communities) of computer science: PL (programming language), SE (software engineering), OS (operating system), networking, storage, theory; more recently, NLP (natural language processing), and ML (machine learning). 
The database community is centered around the people interested in making the database (the product) better instead of pure intellectual/research interests; it is, therefore, a practical and multi-disciplinary field.
This makes databases awesome but also hard to learn.

As complex as it is, the boundaries of the building blocks within a database are clear after decades of research and real-world operations.
The recent (and state-of-the-art) [Apache DataFusion](https://github.com/apache/datafusion) project is a good example of building a database using well-defined industry standards like [Apache Arrow](https://arrow.apache.org), and [Apache Parquet](https://parquet.apache.org). 
Without home-grown solutions for storage and in-memory representation, DataFusion is [comparable or even better](https://github.com/apache/datafusion/files/15149988/DataFusion_Query_Engine___SIGMOD_2024-FINAL-mk4.pdf) than alternatives like [DuckDB](https://github.com/duckdb/duckdb). 

This document aims to explain how modern query engines (i.e., [OLAP](https://aws.amazon.com/compare/the-difference-between-olap-and-oltp)) work, step by step, from SQL to results:
```{mermaid}
flowchart LR
   id1[SQL text] --> |SQL parser| id2[SQL statement] 
   id2 --> |Query planner| id3[Logical plan] --> |Query optimizer| id4[Optimized logical plan] --> |Physical planner| id5
   id5[Physical plan] --> |Execution| id7[Output]

```



::: {.callout-note}
This working-in-progress blog post explains how a database query engine works. 
This is a blog post I hoped I knew when I was younger.

I aim to make multi-year efforts to edit and improve it as I learn more about databases.
I sometimes dreamed that this post could evolve to be the database equivalent of the [OSTEP](https://pages.cs.wisc.edu/~remzi/OSTEP/) book (might be too ambitious, though).
:::


## Section 1: End-To-End View

### Input 

#### Table definition
We have the following two tables (adapted from [TPC-H spec](https://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.1.pdf)): `lineitem` and `orders`.
The `lineitem` defines the the shipment dates, while the `order` defines order details. 

```{mermaid}
erDiagram
  lineitem {
      int l_orderkey
      int l_linenumber
      date l_shipdate
      date l_commitdate
      date l_receiptdate
      string l_shipmode
      string l_comment
  }
  orders {
      int o_orderkey
      date o_orderdate
      string o_orderpriority
      string o_clerk
      string o_comment
  }
```


#### SQL query
Let's say we have this simple query (adapted from [TPC-H query 5](https://github.com/apache/datafusion/blob/main/benchmarks/queries/q5.sql)), which finds the `l_orderkey`, `l_shipdate`, and `o_orderdate` of orders that were placed in `1994`.
```sql
SELECT
    l_orderkey, l_shipdate, o_orderdate
FROM
    orders
JOIN
    lineitem ON l_orderkey = o_orderkey
WHERE
    o_orderdate >= DATE '1994-01-01'
    AND o_orderdate < DATE '1995-01-01';
```


### Output
The query is pretty simple; it joins two tables on the order key and then filters the results based on the order date.
If everything goes well, we should get results similar to this:
```txt
+------------+------------+-------------+
| l_orderkey | l_shipdate | o_orderdate |
+------------+------------+-------------+
| 1          | 1994-06-01 | 1994-05-01  |
+------------+------------+-------------+
```

## Section 2: Parsing

I skipped it for now as it is mostly orthogonal to the data system pipelines.

#### Input
The SQL query text.


#### Output
Structured [`statement`](https://docs.rs/datafusion/37.1.0/datafusion/sql/parser/enum.Statement.html) from the SQL (significantly simplified for brevity):

```txt
from: [
  TableWithJoins {
    relation: Table {
      name: ObjectName([
        Ident {
          value: "orders",
          quote_style: None,
        },
      ]),
    },
    joins: [
      Join {
        relation: Table {
          name: ObjectName([
            Ident {
              value: "lineitem",
              quote_style: None,
            },
          ]),
        },
        join_operator: Inner(
          On(
            BinaryOp {
              left: Identifier(
                Ident {
                  value: "l_orderkey",
                  quote_style: None,
                },
              ),
              op: Eq,
              right: Identifier(
                Ident {
                  value: "o_orderkey",
                  quote_style: None,
                },
              ),
            },
          ),
        ),
      },
    ],
  },
],
selection: Some(
  BinaryOp {
    left: BinaryOp {
      left: Identifier(
        Ident {
          value: "o_orderdate",
          quote_style: None,
        },
      ),
      op: GtEq,
      right: TypedString {
        data_type: Date,
        value: "1994-01-01",
      },
    },
    op: And,
    right: BinaryOp {
      left: Identifier(
        Ident {
          value: "o_orderdate",
          quote_style: None,
        },
      ),
      op: Lt,
      right: TypedString {
        data_type: Date,
        value: "1995-01-01",
      },
    },
  },
),
```

## Section 3: Query Planning
#### Input
The query statement from the last step.

#### Output
The logical query plan is something like this:

```txt
Projection: lineitem.l_orderkey, lineitem.l_shipdate, orders.o_orderdate
  Filter: orders.o_orderdate >= CAST(Utf8("1994-01-01") AS Date32) AND orders.o_orderdate < CAST(Utf8("1995-01-01") AS Date32)
    Inner Join:  Filter: lineitem.l_orderkey = orders.o_orderkey
      TableScan: orders
      TableScan: lineitem
```

Plot it as a tree.
```{dot}
//| fig-height: 2
digraph {
    graph[]
    2[shape=box label="Projection: lineitem.l_orderkey, lineitem.l_shipdate, orders.o_orderdate"]
    3[shape=box label="Filter: orders.o_orderdate >= CAST(Utf8(_1994-01-01_) AS Date32) AND orders.o_orderdate < CAST(Utf8(_1995-01-01_) AS Date32)"]
    2 -> 3 [arrowhead=none, arrowtail=normal, dir=back]
    4[shape=box label="Inner Join:  Filter: lineitem.l_orderkey = orders.o_orderkey"]
    3 -> 4 [arrowhead=none, arrowtail=normal, dir=back]
    5[shape=box label="TableScan: orders"]
    4 -> 5 [arrowhead=none, arrowtail=normal, dir=back]
    6[shape=box label="TableScan: lineitem"]
    4 -> 6 [arrowhead=none, arrowtail=normal, dir=back]
}
```


Logical vs physical. 

Todo: describe why we must distinguish between physical and logical plans.

## Section 4: Query Optimizing

#### Input
The (unoptimized) logical plan from the last step.

#### Output
An optimized logical plan.

```txt
Projection: lineitem.l_orderkey, lineitem.l_shipdate, orders.o_orderdate
  Inner Join: orders.o_orderkey = lineitem.l_orderkey
    Filter: orders.o_orderdate >= Date32("8766") AND orders.o_orderdate < Date32("9131")
      TableScan: orders projection=[o_orderkey, o_orderdate], partial_filters=[orders.o_orderdate >= Date32("8766"), orders.o_orderdate < Date32("9131")]
    TableScan: lineitem projection=[l_orderkey, l_shipdate]
```

```{dot}
//| fig-height: 2
digraph {
    graph[]
    2[shape=box label="Projection: lineitem.l_orderkey, lineitem.l_shipdate, orders.o_orderdate"]
    3[shape=box label="Inner Join: orders.o_orderkey = lineitem.l_orderkey"]
    2 -> 3 [arrowhead=none, arrowtail=normal, dir=back]
    4[shape=box label="Filter: orders.o_orderdate >= Date32(_8766_) AND orders.o_orderdate < Date32(_9131_)"]
    3 -> 4 [arrowhead=none, arrowtail=normal, dir=back]
    5[shape=box label="TableScan: orders projection=[o_orderkey, o_orderdate], partial_filters=[orders.o_orderdate >= Date32(_8766_), orders.o_orderdate < Date32(_9131_)]"]
    4 -> 5 [arrowhead=none, arrowtail=normal, dir=back]
    6[shape=box label="TableScan: lineitem projection=[l_orderkey, l_shipdate]"]
    3 -> 6 [arrowhead=none, arrowtail=normal, dir=back]
}
// End DataFusion GraphViz Plan
```

Note the difference between an unoptimized and an optimized plan!
The `Filter` has been pushed down to lower-level nodes. Part of the projection has been embedded in the `TableScan`.

## Section 5: Physical Planning

#### Input
A logical plan.

#### Output
A physical plan. Unlike logical plans, physical plans are more concrete about what to do; here's an example:

```txt
Physical plan:
ProjectionExec: expr=[l_orderkey@1 as l_orderkey, l_shipdate@2 as l_shipdate, o_orderdate@0 as o_orderdate]
  CoalesceBatchesExec: target_batch_size=8192
    HashJoinExec: mode=Partitioned, join_type=Inner, on=[(o_orderkey@0, l_orderkey@0)], projection=[o_orderdate@1, l_orderkey@2, l_shipdate@3]
      CoalesceBatchesExec: target_batch_size=8192
        RepartitionExec: partitioning=Hash([o_orderkey@0], 8), input_partitions=8
          CoalesceBatchesExec: target_batch_size=8192
            FilterExec: o_orderdate@1 >= 8766 AND o_orderdate@1 < 9131
              RepartitionExec: partitioning=RoundRobinBatch(8), input_partitions=1
                CsvExec: file_groups={1 group: [[Users/xiangpeng/work/coding/db-ml/bin/example-data/orders.csv]]}, projection=[o_orderkey, o_orderdate], has_header=true
      CoalesceBatchesExec: target_batch_size=8192
        RepartitionExec: partitioning=Hash([l_orderkey@0], 8), input_partitions=8
          RepartitionExec: partitioning=RoundRobinBatch(8), input_partitions=1
            CsvExec: file_groups={1 group: [[Users/xiangpeng/work/coding/db-ml/bin/example-data/lineitem.csv]]}, projection=[l_orderkey, l_shipdate], has_header=true
```
We can also plot a physical plan to a tree graph:

```{dot}
//| fig-height: 4
//| fig-width: 8
digraph {
    1[shape=box label="ProjectionExec: expr=[l_orderkey@1 as l_orderkey, l_shipdate@2 as l_shipdate, o_orderdate@0 as o_orderdate]", tooltip=""]
    2[shape=box label="CoalesceBatchesExec: target_batch_size=8192", tooltip=""]
    1 -> 2 [arrowhead=none, arrowtail=normal, dir=back]
    3[shape=box label="HashJoinExec: mode=Partitioned, join_type=Inner, on=[(o_orderkey@0, l_orderkey@0)], projection=[o_orderdate@1, l_orderkey@2, l_shipdate@3]", tooltip=""]
    2 -> 3 [arrowhead=none, arrowtail=normal, dir=back]
    4[shape=box label="CoalesceBatchesExec: target_batch_size=8192", tooltip=""]
    3 -> 4 [arrowhead=none, arrowtail=normal, dir=back]
    5[shape=box label="RepartitionExec: partitioning=Hash([o_orderkey@0], 8), input_partitions=8", tooltip=""]
    4 -> 5 [arrowhead=none, arrowtail=normal, dir=back]
    6[shape=box label="CoalesceBatchesExec: target_batch_size=8192", tooltip=""]
    5 -> 6 [arrowhead=none, arrowtail=normal, dir=back]
    7[shape=box label="FilterExec: o_orderdate@1 >= 8766 AND o_orderdate@1 < 9131", tooltip=""]
    6 -> 7 [arrowhead=none, arrowtail=normal, dir=back]
    8[shape=box label="RepartitionExec: partitioning=RoundRobinBatch(8), input_partitions=1", tooltip=""]
    7 -> 8 [arrowhead=none, arrowtail=normal, dir=back]
    9[shape=box label="CsvExec: file_groups={1 group: [[orders.csv]]}, projection=[o_orderkey, o_orderdate], has_header=true", tooltip=""]
    8 -> 9 [arrowhead=none, arrowtail=normal, dir=back]
    10[shape=box label="CoalesceBatchesExec: target_batch_size=8192", tooltip=""]
    3 -> 10 [arrowhead=none, arrowtail=normal, dir=back]
    11[shape=box label="RepartitionExec: partitioning=Hash([l_orderkey@0], 8), input_partitions=8", tooltip=""]
    10 -> 11 [arrowhead=none, arrowtail=normal, dir=back]
    12[shape=box label="RepartitionExec: partitioning=RoundRobinBatch(8), input_partitions=1", tooltip=""]
    11 -> 12 [arrowhead=none, arrowtail=normal, dir=back]
    13[shape=box label="CsvExec: file_groups={1 group: [[lineitem.csv]]}, projection=[l_orderkey, l_shipdate], has_header=true", tooltip=""]
    12 -> 13 [arrowhead=none, arrowtail=normal, dir=back]
}
```

::: {.callout-note}
Note that a physical plan has much more details than a logical plan; it contains everything needed to execute the query!
:::
(Optional: we often have physical optimizers that optimize on a physical plan. Omitted here for simplicity)


## Section 6: Query Execution
#### Input
A physical plan

#### Output
The final output is like this:

```txt
+------------+------------+-------------+
| l_orderkey | l_shipdate | o_orderdate |
+------------+------------+-------------+
| 1          | 1994-06-01 | 1994-05-01  |
+------------+------------+-------------+
```

### How to execute a physical plan?

The simplest execution model is [pull-based execution](https://justinjaffray.com/query-engines-push-vs.-pull/), which implements a [post-order traversal](https://www.freecodecamp.org/news/binary-search-tree-traversal-inorder-preorder-post-order-for-bst/) of the physical plan.
For a tree (like blow), we get a traversal order of `D -> E -> B -> F -> G -> C -> A`:
![](f4.png)

Applying our physical graph above, we get an execution order of:

1. [`CsvExec (orders.csv)`](https://docs.rs/datafusion/37.1.0/datafusion/datasource/physical_plan/struct.CsvExec.html)

2. [`RepartitionExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/repartition/struct.RepartitionExec.html)

3. [`FilterExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/filter/struct.FilterExec.html)

4. [`CoalesceBatchesExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/coalesce_batches/struct.CoalesceBatchesExec.html)

5. [`RepartitionExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/repartition/struct.RepartitionExec.html)

6. [`CoalesceBatchesExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/coalesce_batches/struct.CoalesceBatchesExec.html)

7. [`CsvExec (lineitem.csv)`](https://docs.rs/datafusion/37.1.0/datafusion/datasource/physical_plan/struct.CsvExec.html)

8. [`RepartitionExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/repartition/struct.RepartitionExec.html)

9. [`RepartitionExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/repartition/struct.RepartitionExec.html)

10. [`CoalesceBatchesExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/coalesce_batches/struct.CoalesceBatchesExec.html)

11. [`HashJoinExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/joins/struct.HashJoinExec.html)

12. [`CoalesceBatchesExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/coalesce_batches/struct.CoalesceBatchesExec.html)

13. [`ProjectionExec`](https://docs.rs/datafusion/37.1.0/datafusion/physical_plan/projection/struct.ProjectionExec.html)

The `RepartitionExec` and `CoalesceBatchesExec` are executors that partition the data for multi-thread processing (based on the [Volcano execution](https://w6113.github.io/files/papers/volcanoparallelism-89.pdf) style).

A simplified, single-threaded, no-partitioned execution order would be:
```{mermaid}
graph LR;
    e1["CsvExec (orders.csv)"] --> FilterExec
    FilterExec --> e2 
    e2["CsvExec (lineitem.csv)"] --> HashJoinExec
    HashJoinExec --> ProjectionExec
```

