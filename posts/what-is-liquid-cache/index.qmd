---
title: "What is LiquidCache?"
date: "2025-08-22"
date-modified: "2025-08-22"
description: "Three roles: caching for diskless, state for serverless, and liquid data for compute pushdown."
categories: []
comments:
  giscus: 
    repo: XiangpengHao/blog
toc: true
draft: false 
reference-location: margin
citation-location: margin
---
::: {.callout-warning appearance="simple" icon=false}
## Acknowledgments

This work is supported by [funding](https://xiangpeng.systems/fund/) from:<br>
1.  [InfluxData](https://influxdata.com), [Bauplan](https://www.bauplanlabs.com), and [SpiralDB](https://spiraldb.com).<br>
2.  The taxpayers of the State of Wisconsin and the federal government.

Your support for science is greatly appreciated!
:::

[LiquidCache](https://github.com/XiangpengHao/liquid-cache) is a new caching infrastructure for the next decade of data analytics.[^5]


At a glance, LiquidCache is a caching service for object stores that serves diverse analytical applications.
Under the hood, LiquidCache is ultra-optimized for compute pushdown, larger‑than‑memory datasets, and network‑efficient data transfer.

![LiquidCache overview. It caches different object store sources and serves different analytical applications.](./liquid-cache-overview.png){width=80%}

It is built on open standards: [Parquet](https://parquet.apache.org/) for data storage, [DataFusion](https://github.com/apache/datafusion) as the query engine, and [Arrow Flight](https://arrow.apache.org/docs/format/Flight.html) for data transfer.
This makes LiquidCache highly composable; you can easily integrate it into your existing analytics stack.

This blog post discusses the three critical roles of LiquidCache in next-generation analytics: caching for diskless, state management for serverless, and liquid data for compute pushdown.


[^5]: Check out our [research paper](https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf) (VLDB 2026) for more technical details.

## Caching for diskless

#### We like S3
1. Simple durability: 11 nines of durability—you never have to worry about data loss.
2. Simple scalability: virtually unlimited space and throughput.

#### But S3 is slow and expensive
1. ≈100 ms first‑byte latency plus transfer latency; this quickly adds up when multiple round‑trips are needed to fetch data. [^2]
2. Storage, request, and data‑transfer/egress costs; prices have remained unchanged for a decade even as underlying hardware has become ~20× cheaper.

![S3 prices have barely changed for a decade, despite ~20× reductions in underlying hardware costs, [credit to Andrew Lamb](https://x.com/andrewlamb1111/status/1909681433452724444)](./s3-price.jpg){width=80%}


#### LiquidCache: foundation of diskless analytics
1. Caches are everywhere[^1]: compute‑local caches (e.g., Snowflake/Databricks local NVMe, Spark host caches), shared‑nothing caches, and cache services.
2. DLC trilemma: among durability, low latency, and low cost, you can only choose two [^3].
![](./DLC.png){width=50%}

[^1]: [The Five-Minute Rule for the Cloud: Caching in Analytics Systems](https://andrew.nerdnetworks.org/other/CIDR_2025_Cloud_5_Minute_Rule.pdf)
[^2]: [Exploiting Cloud Object Storage for High-Performance Analytics](https://www.vldb.org/pvldb/vol16/p2769-durner.pdf)
[^3]: [The Cloud Storage Triad: Latency, Cost, Durability](https://materializedview.io/p/cloud-storage-triad-latency-cost-durability)

## State management for serverless 

#### We like serverless
1. Simple scalability: automatic horizontal scaling and fine‑grained billing.
2. Lower cost via higher utilization and elasticity; zero servers to manage.

#### But serverless analytics are slow and expensive 
1. S3 is both too slow and too expensive. 
2. You can't build a sticky compute‑local cache: serverless compute is one‑shot, ephemeral, and stateless.

#### LiquidCache: the missing piece for serverless analytics
In practice, most production analytics pin workloads to EC2‑like servers with a compute‑local cache for predictable performance.

With LiquidCache, all compute nodes can be serverless because they can connect to the shared LiquidCache service, which is deployed on conventional EC2 instances.

![](./serverless.png){width=60%}

## Liquid data for compute pushdown 

#### We like Parquet
1. All major query engines support it (DataFusion, Spark, Trino, DuckDB, Snowflake, BigQuery, and more).
2. It is battle‑tested and keeps evolving (e.g., page indexes, new encodings).
3. It is under open, stable governance (Apache Software Foundation), so your data is in good hands.

#### But sometimes we want more aggressive performance
1. There are better encodings and compression schemes out there.
2. Parquet is critical data infrastructure: it evolves cautiously to keep your data safe and stable—it can't try new research today and abandon your data tomorrow.

#### LiquidCache: cache-only, pushdown-optimized data representation
1. LiquidCache uses state‑of‑the‑art encodings and compression chosen by the workload. [^4]
2. Liquid data is invisible to the rest of the ecosystem: it is cache‑only. This means it can freely change its layout, adding or removing encodings without breaking any user code.
3. LiquidCache transparently, progressively, and selectively transcodes Parquet data to the liquid format.
4. Liquid data is designed for efficient pushdown to save both compute and network resources. 

Without any changes to Parquet, LiquidCache takes care of the performance optimizations.

![](./liquid-data.jpg){width=80%}

[^4]: The liquid format is heavily inspired by [Vortex](https://github.com/vortex-data/vortex). We plan to support a Vortex backend in the future. 

## Conclusions

LiquidCache is the one‑stop shop for diskless, serverless, and pushdown‑native analytics. 

It is built on open standards (Parquet, Arrow Flight, DataFusion) for easy integration and stable governance.

It optimizes for compute pushdown, larger‑than‑memory datasets, and network‑efficient data transfer.
 
#### Who are we?
- LiquidCache started as a research project at UW‑Madison [ADSL](https://research.cs.wisc.edu/adsl/) led by [Xiangpeng Hao](https://xiangpeng.systems).
- It was made possible by a research gift from [InfluxData](https://influxdata.com). One year later, [SpiralDB](https://spiraldb.com) and [Bauplan](https://www.bauplanlabs.com) also joined the journey.[^6]
- LiquidCache will remain a public‑benefit project in appreciation of the support from taxpayers, research gifts, and the open‑source community.

[^6]: Support our research [here](https://xiangpeng.systems/fund/)!
